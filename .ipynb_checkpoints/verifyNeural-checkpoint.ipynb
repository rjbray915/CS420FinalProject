{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojbmaW3D26WB",
    "outputId": "66370790-50eb-450a-de48-b5b29172da7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      " 1.13ef.pdf\n",
      " 1.13ma.pdf\n",
      "'3 5 Concert Report.gdoc'\n",
      "'Abstarct for AAIC_FAIR REACH_rv_rpl[4927].docx'\n",
      "'Abstarct for AAIC_FAIR REACH_v0.docx'\n",
      " assignment6_rbray2.gdoc\n",
      " ATT00001\n",
      "'background for engl360 paper.gdoc'\n",
      "'Book report.gdoc'\n",
      " Bray_Rob_Covid_Paper.gdoc\n",
      "'CALC 148'\n",
      "'Colab Notebooks'\n",
      "'Commercial Viability of AI-generated Music.gslides'\n",
      "'Compsci grade.gsheet'\n",
      "'Copy of 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Copy of Review- Robots in Classroom.gdoc'\n",
      "'Copy of RobBray12_3_ 2021Timesheet - Biweekly-Blank(1).gsheet'\n",
      "'Copy of RobBray12_3_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Copy of Rob_Bray_7_16_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Copy of Rob_Bray_8_13_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'COSC 130'\n",
      " cs361_assign1.gdoc\n",
      " cs366_pa1_rbray2.gdoc\n",
      " data_entry_resume.gdoc\n",
      " dataset.zip\n",
      " deeplearning2_24.pdf\n",
      "'Discussion 9 21.gdoc'\n",
      " eaat5954.full.gdoc\n",
      " eaat5954.full.pdf\n",
      "'EF 157'\n",
      "'ENGL 290'\n",
      "'English Paper Outline.gdoc'\n",
      " Essay.gdoc\n",
      " exam2_rbray2.gdoc\n",
      "'FAIR_no videos.pptx'\n",
      "'FALL WORK HOURS.gsheet'\n",
      "'FRED-meeting notes.txt'\n",
      "'FRED Technical Details & Challenges.gdoc'\n",
      "'Getting started.pdf'\n",
      "'grad school.gdoc'\n",
      " group9_writeup.gdoc\n",
      " IMG-0455.jpg\n",
      "'Interview Questions.gdoc'\n",
      " intro_slides.gslides\n",
      " lab5_rbray2.gdoc\n",
      " mabe_resume.gdoc\n",
      " mabe_resume.pdf\n",
      " MasterExperiment1.gsheet\n",
      "'Math grade.gsheet'\n",
      " ML_assign2_rbray2.gdoc\n",
      " ML_assignment3_rbray2.gdoc\n",
      "'ML midterm.gsheet'\n",
      " notes.md\n",
      " os_project3_writeup.gdoc\n",
      "'PASS 3-28.gdoc'\n",
      "'PASS 4-12-22.gdoc'\n",
      " PASS_code_flow.gslides\n",
      " PASS_code_flow.odp\n",
      " pass_qt\n",
      " passTutorial.gdoc\n",
      "'Poster Outline - Line chart 1.gsheet'\n",
      "'prog lab.gsheet'\n",
      " project1.gsheet\n",
      " Project_2_Individual_Reflection.gdoc\n",
      " project_proposal.gdoc\n",
      " Project-Proposal-template-1.gdoc\n",
      "'Project Tracking.gsheet'\n",
      "'Qualitative Research Proposal.gdoc'\n",
      " rbray2_as2.gdoc\n",
      " rbray2_assignment4.gdoc\n",
      " rbray2_assignment5.gdoc\n",
      " rbray2_bias.gdoc\n",
      " rbray2_dnd.gcode\n",
      " rbray2_dnd.zip\n",
      " rbray2_lab3Report.gdoc\n",
      " rbray2_lab4.gdoc\n",
      " rbray2_os_final.gdoc\n",
      " rbray2_os_midterm.gdoc\n",
      " rbray2_PA2.gdoc\n",
      " rbray2_project_1.gdoc\n",
      " rbray2_project2.gdoc\n",
      " rbray2_report.gdoc\n",
      " rbray2_WA2_writeup.gdoc\n",
      " rbray2_WA3.gdoc\n",
      " rbray2_WA4.gdoc\n",
      "'RCT 3 25.gdoc'\n",
      " realtimestt\n",
      "'Report (1).gdoc'\n",
      "'Report (2).gdoc'\n",
      " Report.gdoc\n",
      " research_assign5.gdoc\n",
      "'Research Docs Summary I.gdoc'\n",
      " resume.gdoc\n",
      "'Review- Robots in Classroom.docx'\n",
      "'RobBray10_24_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_10_8_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'RobBray11_21_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'RobBray11_4_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'RobBray12_19_ 2021Timesheet - Biweekly-Blank(1).gsheet'\n",
      "'RobBray1_2_ 2021Timesheet - Biweekly-Blank(1).gsheet'\n",
      "'RobBray_1_2_2022Timesheet - Biweekly-Blank.gsheet'\n",
      "'RobBray_1_28_2022Timesheet - Biweekly-Blank.gsheet'\n",
      "'RobBray_1_30_2022Timesheet - Biweekly-Blank.gsheet'\n",
      "'RobBray_2_13_2022Timesheet - Biweekly-Blank.gsheet'\n",
      "'RobBray_2_27_2022Timesheet - Biweekly-Blank(1).gsheet'\n",
      "'RobBray_3_13_2022Timesheet - Biweekly-Blank(1).gsheet'\n",
      "'RobBray_3_27_2022Timesheet - Biweekly-Blank(1).gsheet'\n",
      "'Rob Bray 3_28_2021Timesheet - Biweekly.gsheet'\n",
      "'RobBray_4_10_2022Timesheet - Biweekly-Blank.gsheet'\n",
      "'Rob Bray 4_11_2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'RobBray_4_22_2022Timesheet - Biweekly-Blank.gsheet'\n",
      "'Rob Bray 4_25_2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_5_23 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_6_18 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_6_4 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_7_2_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_7_30_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_8_27_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      "'Rob_Bray_9_10_ 2021Timesheet - Biweekly-Blank.xlsx'\n",
      " rob_bray_ch_12.gdoc\n",
      " rob_bray_ch_14.gdoc\n",
      " rob_bray_ch24.gdoc\n",
      " rob_bray_ch_4.gdoc\n",
      " rob_bray_DAW.gdoc\n",
      "'Rob Bray ENGL 290 Secondary Paper FINAL (1).gdoc'\n",
      " rob_bray_final_report.gdoc\n",
      " RobBrayMasterExperiment.gsheet\n",
      " rob_bray_PAW.gdoc\n",
      " rob_bray_proposal.gdoc\n",
      " rob_bray_rbray2_assignment1.gdoc\n",
      " robBray_rbray2_MBO.gdoc\n",
      " rob_bray_resume.gdoc\n",
      " RobBrayResume_update.docx\n",
      " RobBrayResume_update_final.gdoc\n",
      " RobertBray-bod-fellow-application.gdoc\n",
      "'robot arm ideas.gdoc'\n",
      "'Robotic Arm Ideas.gdoc'\n",
      " scientificVoice_robBray.gdoc\n",
      " SD_RobBrayResume_update_final.gdoc\n",
      "'Self-Assessment Questions – Exam 3 – Fall 2020.gdoc'\n",
      " set_of_instructions.gdoc\n",
      " spring22_hours.gsheet\n",
      " static_electricity_paper.gdoc\n",
      "'SUMMER WORK HOURS.gsheet'\n",
      " Tasks.gdoc\n",
      " tethys_func.gslides\n",
      " tethys_func.odp\n",
      "'Thank you letter.gdoc'\n",
      "'TODO 10 22.gdoc'\n",
      "'TS5-7 PROJECT 2'\n",
      "'Untitled document (1).gdoc'\n",
      "'Untitled document (2).gdoc'\n",
      "'Untitled document (3).gdoc'\n",
      "'Untitled document (4).gdoc'\n",
      "'Untitled document (5).gdoc'\n",
      "'Untitled document (6).gdoc'\n",
      "'Untitled document.gdoc'\n",
      "'Untitled presentation (1).gslides'\n",
      "'Untitled presentation.gslides'\n",
      "'Untitled spreadsheet.gsheet'\n",
      " updated_resume.gdoc\n",
      " verifyNeural.ipynb\n",
      "'Virtual Reality.gform'\n",
      " water.gsheet\n",
      "'website demo.gdoc'\n",
      "'WORK HOURS.gdoc'\n",
      "Archive:  /content/drive/MyDrive/dataset.zip\n",
      "replace dataset/flowers/astilbe/10091895024_a2ea04cda6_c.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls \"/content/drive/MyDrive/\"\n",
    "!unzip \"/content/drive/MyDrive/dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2yuw9lZ2p-5",
    "outputId": "bfcb45ff-9a36-4c5a-b648-d27263adcd61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygad in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (2.16.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from pygad) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from pygad) (1.22.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (3.0.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (9.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from matplotlib->pygad) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\rbfre\\documents\\github\\cs420finalproject\\.venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pygad\n",
    "\n",
    "import tensorflow as tf\n",
    "import pygad as pg\n",
    "import pygad.kerasga\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "imgDir = os.path.join('dataset', 'flowers')\n",
    "imgSize = 30\n",
    "batchSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJnshWkb2p_B",
    "outputId": "5dc7e2bf-b41e-484e-8c54-1452dfe8c063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13838 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(imgDir, image_size=(imgSize,imgSize), batch_size=batchSize)\n",
    "testData = dataset.take(25)\n",
    "trainData = dataset.skip(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QCdcK-crBdo",
    "outputId": "5923b966-572a-48cb-bb14-b33eeca3abb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 10  2 ...  9  9 11]\n"
     ]
    }
   ],
   "source": [
    "# print(trainData.unbatch())\n",
    "# for x,y in trainData.unbatch():\n",
    "#   print(y)\n",
    "yTrain = np.asarray([y for x,y in trainData.unbatch()])\n",
    "\n",
    "#make sure its divisible\n",
    "# xTrain, yTrain = xTrain[:len(xTrain)-2], yTrain[:len(yTrain)-2]\n",
    "# xTest, yTest = xTest[:len(xTrain)-2], yTest[:len(yTrain)-2]\n",
    "print(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5tcUwkg2p_F",
    "outputId": "df64b3b3-f192-4b96-ec68-fff59ec672ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 30, 30, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 4)         112       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 8)         296       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                75726     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,134\n",
      "Trainable params: 76,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build verification model\n",
    "inputs = tf.keras.layers.Input(shape=(imgSize, imgSize, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=4, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(units=14, activation='softmax')(x)\n",
    "\n",
    "# make model checkpoint to save weights\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\"verifyWeights\", monitor=\"sparse_categorical_accuracy\", save_best_only=True)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='sparse_categorical_accuracy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x42bpf0S2p_I",
    "outputId": "8b91d194-53ff-4d13-8aaa-4833896df654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SkipDataset element_spec=(TensorSpec(shape=(None, 30, 30, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))> \n",
      " <TakeDataset element_spec=(TensorSpec(shape=(None, 30, 30, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))> \n",
      " <BatchDataset element_spec=(TensorSpec(shape=(None, 30, 30, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))> <bound method DatasetV2.cardinality of <BatchDataset element_spec=(TensorSpec(shape=(None, 30, 30, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>>\n",
      "Epoch 1/5\n",
      "84/84 [==============================] - ETA: 0s - loss: 14.3089 - sparse_categorical_accuracy: 0.1452INFO:tensorflow:Assets written to: verifyWeights/assets\n",
      "84/84 [==============================] - 13s 95ms/step - loss: 14.3089 - sparse_categorical_accuracy: 0.1452\n",
      "Epoch 2/5\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 3.4279 - sparse_categorical_accuracy: 0.1924INFO:tensorflow:Assets written to: verifyWeights/assets\n",
      "84/84 [==============================] - 11s 95ms/step - loss: 3.4131 - sparse_categorical_accuracy: 0.1922\n",
      "Epoch 3/5\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 2.5243 - sparse_categorical_accuracy: 0.2215INFO:tensorflow:Assets written to: verifyWeights/assets\n",
      "84/84 [==============================] - 11s 96ms/step - loss: 2.5182 - sparse_categorical_accuracy: 0.2230\n",
      "Epoch 4/5\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 2.2040 - sparse_categorical_accuracy: 0.2957INFO:tensorflow:Assets written to: verifyWeights/assets\n",
      "84/84 [==============================] - 11s 96ms/step - loss: 2.1998 - sparse_categorical_accuracy: 0.2970\n",
      "Epoch 5/5\n",
      "81/84 [===========================>..] - ETA: 0s - loss: 1.9732 - sparse_categorical_accuracy: 0.3587INFO:tensorflow:Assets written to: verifyWeights/assets\n",
      "84/84 [==============================] - 11s 96ms/step - loss: 1.9693 - sparse_categorical_accuracy: 0.3589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66efafd910>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainData, '\\n', testData, '\\n', dataset, dataset.cardinality)\n",
    "model.fit(trainData, epochs=5, callbacks=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k6nWwSz2p_L",
    "outputId": "0015ea76-35b8-49c2-a293-90e128c74946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 94ms/step - loss: 2.3358 - sparse_categorical_accuracy: 0.2831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3357768058776855, 0.28312501311302185]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpUykTWVzJXh",
    "outputId": "1f5892f5-bc1d-4104-e05b-1f9f0dc819a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10638,)\n"
     ]
    }
   ],
   "source": [
    "print(yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Po3YR4s68gsi"
   },
   "outputs": [],
   "source": [
    "# make a kerasGA\n",
    "myGA = pg.kerasga.KerasGA(model=model, num_solutions=10)\n",
    "\n",
    "# this is our fitness func\n",
    "def fitFunc(solution, solutionIndx):\n",
    "    print('in fitness func')\n",
    "    weightsMatrix = pg.kerasga.model_weights_as_matrix(model=model, weights_vector=solution)\n",
    "    model.set_weights(weights=weightsMatrix)\n",
    "    preds = model.predict(trainData)\n",
    "    sparseCE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    fitness = 1.0 / (sparseCE(yTrain, preds).numpy() + 0.0000000000001)\n",
    "    return fitness\n",
    "\n",
    "# progress callback for GA\n",
    "def genCallback(ganstance):\n",
    "    print(f'Generation = {gaInstance.generations_completed}')\n",
    "    print(f'fitness = {gaInstance.best_solution()[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1-GHk2cQoeam"
   },
   "outputs": [],
   "source": [
    "# now make a GA instance with our variables\n",
    "numGen = 1\n",
    "numParents = 5\n",
    "initPopulation = myGA.population_weights\n",
    "\n",
    "gaInstance = pg.GA(num_generations=numGen,\n",
    "                   num_parents_mating=numParents,\n",
    "                   initial_population=initPopulation,\n",
    "                   fitness_func=fitFunc,\n",
    "                   on_generation=genCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "evAwFbJt_jwE",
    "outputId": "74c92b0e-b1d2-477d-eb9c-918d03df0546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n",
      "in fitness func\n"
     ]
    }
   ],
   "source": [
    "gaInstance.run()\n",
    "gaInstance.plot_fitness(title=\"woO baby\", linewidth=4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "verifyNeural.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a0f82c626366566345e874f86ac566c29ee2b388954eabd0fa490f69ee941129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
